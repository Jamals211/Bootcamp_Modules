{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Big Data\n",
    "\n",
    "#### Volume, Velocity, Variety, Veracity(uncertainty of data-fake reviews)\n",
    "\n",
    "#  Hadoop-Google\n",
    "####           *process large amounts of data-splitting data across distributed file systems\n",
    "####           *HDFS-Hadoop Distributed File System-store data across server clusters (groups of computers)\n",
    "####           *Scalable-handles influxes of data\n",
    "####           *Fault-tolerant-handles hardware failure\n",
    "####           *Distributed-Spread across multiple servers\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Hadoop distributes for storage and processing of data through cluster (group of connected computers that work together to store and perform tasks on a dataset)        \n",
    "#### *Need to set up all three components across multiple machines, make sure each one has suffcient resources and configured for optimal performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MapReduce\n",
    "####           *programming model and processing technique\n",
    "####           *Enables processing large data spread across the cluster in HDFS performing tasks for each file system\n",
    "####           *Splitting up data large datasets\n",
    "####           *Distributing and processing data on your cluster (group of connected computers working together to store and perform tasks on a dataset)\n",
    "####           *Built on mapping(process of assigning the same job to each of the computers)\n",
    "####           *Reducing-aggregate the results(combine the results)\n",
    "####           *Works faster on divided datasets in smaller batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####           *Map function takes a small piece of input and then converts the data into key-value pairs\n",
    "####           *Parts of the word count process:\n",
    "#####           *Input-entire file is fed to the word counter\n",
    "#####          *Splitting-Each line of text is sperated\n",
    "#####          *Mapping-Each word in every line is assigned a value of 1\n",
    "#####          *Shuffling-Words are combined and organized alphabetically (list of words' values)\n",
    "#####          *Reducing-list of values are summed for each word\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YARN\n",
    "####           *Yet Another Resource Negotiator\n",
    "####           *Manages and allocates resources across clusters and assigns tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"../Program/Modules/16.user_data.csv\"\n",
    "payment=\"../Program/Modules/16.user_payment.csv\"\n",
    "user_data=pd.read_csv(data)\n",
    "user_payment=pd.read_csv(payment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>active_user</th>\n",
       "      <th>street_address</th>\n",
       "      <th>state</th>\n",
       "      <th>username</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Cletus</td>\n",
       "      <td>Lithcow</td>\n",
       "      <td>False</td>\n",
       "      <td>78309 Riverside Way</td>\n",
       "      <td>Virginia</td>\n",
       "      <td>ibearham0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Caz</td>\n",
       "      <td>Felgat</td>\n",
       "      <td>False</td>\n",
       "      <td>83 Hazelcrest Place</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>wwaller1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Kerri</td>\n",
       "      <td>Crowson</td>\n",
       "      <td>False</td>\n",
       "      <td>112 Eliot Pass</td>\n",
       "      <td>North Carolina</td>\n",
       "      <td>ichesnut2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Freddie</td>\n",
       "      <td>Caghy</td>\n",
       "      <td>False</td>\n",
       "      <td>15 Merchant Way</td>\n",
       "      <td>New York</td>\n",
       "      <td>tsnarr3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Sadella</td>\n",
       "      <td>Deuss</td>\n",
       "      <td>False</td>\n",
       "      <td>079 Acker Avenue</td>\n",
       "      <td>Tennessee</td>\n",
       "      <td>fwherrit4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>996</td>\n",
       "      <td>Barb</td>\n",
       "      <td>Yushachkov</td>\n",
       "      <td>True</td>\n",
       "      <td>66 Rockefeller Hill</td>\n",
       "      <td>Florida</td>\n",
       "      <td>lcripwellrn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>997</td>\n",
       "      <td>Erena</td>\n",
       "      <td>Canadas</td>\n",
       "      <td>False</td>\n",
       "      <td>39 Ludington Drive</td>\n",
       "      <td>Minnesota</td>\n",
       "      <td>pmerigonro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>998</td>\n",
       "      <td>Dexter</td>\n",
       "      <td>Gosneye</td>\n",
       "      <td>True</td>\n",
       "      <td>3 Melody Road</td>\n",
       "      <td>Florida</td>\n",
       "      <td>eephgraverp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>999</td>\n",
       "      <td>Sammy</td>\n",
       "      <td>Gabbatiss</td>\n",
       "      <td>True</td>\n",
       "      <td>50 Gale Street</td>\n",
       "      <td>Washington</td>\n",
       "      <td>kdenajerarq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1000</td>\n",
       "      <td>Ailyn</td>\n",
       "      <td>Bourges</td>\n",
       "      <td>True</td>\n",
       "      <td>41 Prentice Junction</td>\n",
       "      <td>South Carolina</td>\n",
       "      <td>lruffeyrr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id first_name   last_name  active_user        street_address  \\\n",
       "0       1     Cletus     Lithcow        False   78309 Riverside Way   \n",
       "1       2        Caz      Felgat        False   83 Hazelcrest Place   \n",
       "2       3      Kerri     Crowson        False        112 Eliot Pass   \n",
       "3       4    Freddie       Caghy        False       15 Merchant Way   \n",
       "4       5    Sadella       Deuss        False      079 Acker Avenue   \n",
       "..    ...        ...         ...          ...                   ...   \n",
       "995   996       Barb  Yushachkov         True   66 Rockefeller Hill   \n",
       "996   997      Erena     Canadas        False    39 Ludington Drive   \n",
       "997   998     Dexter     Gosneye         True         3 Melody Road   \n",
       "998   999      Sammy   Gabbatiss         True        50 Gale Street   \n",
       "999  1000      Ailyn     Bourges         True  41 Prentice Junction   \n",
       "\n",
       "              state     username  \n",
       "0          Virginia    ibearham0  \n",
       "1           Alabama     wwaller1  \n",
       "2    North Carolina    ichesnut2  \n",
       "3          New York      tsnarr3  \n",
       "4         Tennessee    fwherrit4  \n",
       "..              ...          ...  \n",
       "995         Florida  lcripwellrn  \n",
       "996       Minnesota   pmerigonro  \n",
       "997         Florida  eephgraverp  \n",
       "998      Washington  kdenajerarq  \n",
       "999  South Carolina    lruffeyrr  \n",
       "\n",
       "[1000 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mrjob Library for Python\n",
    "# MRJOB Works by passing a file in the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install MRJOB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mrjob.job import MRJob\n",
    "# class Bacon_count(MRJob): # class inherits from MrJob class to run MapReduce\n",
    "#     def mapper(self, _, line): # mapper() function assign input to key-vlaue pairs\n",
    "        # underscore allows methods to be mapped together\n",
    "        # not chaining anything, use _ to indicate wont use parameter\n",
    "        # line parameter- line of text taken from raw input file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function will loop through each word\n",
    "# call split() method on each line to break the text into a list\n",
    "# each word will convert to lowercase\n",
    "# If words match the search \"bacon\", a key-value pair will: yield \"bacon\", 1\n",
    "# if \"bacon\" appears 3 times then \"bacon\", 1 appears 3 times\n",
    "# Generator Object-fucntion yields this, generator is an iterator ( like a list)\n",
    "#                  -the contents are not stored in memory-used in large files\n",
    "#                  -yield is called, the function is suspended and returns a value\n",
    "#                  -generator wont return another value until next() is called\n",
    "\n",
    "# Shuffle Step After the mapper\n",
    "# No code for this step, occurs because the class inherits from the mrjob library\n",
    "# Organizes key-value pairs-only one key for each unique key and combines into a list\n",
    "\n",
    "\n",
    "# Reducer funciton-Takes three parameters: self, key, and values\n",
    "# Self-instance of the class\n",
    "# Key-key of the key-value pair created in mapper function (key is \"bacon\")\n",
    "# Values-list of values created in mapper-sum all these values-\n",
    "#       -Mapper function- the yiled was used to produce multiple outputs\n",
    "#       -reducer we will produce the key and sum all of the values assiged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [options] [input files]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\15124\\anaconda3\\envs\\PythonData\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3339: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "from mrjob.job import MRJob\n",
    "class Bacon_count(MRJob):\n",
    "    def mapper(self, _, line):\n",
    "        for word in line.split():\n",
    "            if word.lower() == \"bacon\":\n",
    "                yield \"bacon\", 1\n",
    "    def reducer(self, key, values):\n",
    "        yield key, sum(values)\n",
    "if __name__ == '__main__':   # Run the program\n",
    "    Bacon_count.run() \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark\n",
    "#### *Unified analytics engine for large scale data processing\n",
    "#### *Write applications in code that can run on Hadoop\n",
    "#### *Run on Hadoop or stand-alone mode or in the cloud\n",
    "#### *Works with data spread across a cluster (group of computers that works together)\n",
    "#### *In-memory computation instead of disk-based solution(Doesnt talk to HDFS each time and can retain in memory\n",
    "#### *Lazy Evaluation-delays the evalutaion of expression or command until the valve is needed\n",
    "#### (count all product reviews, group them, -Spark is ready to start but need to initiate task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Architecture- Driver, Executors, Cluster Manager\n",
    "\n",
    "#### *Driver-Maintaining app info, responding to input, analyzing/distributing/scheduling work to executors\n",
    "####  ---- assigns work \n",
    "#### *Executors-preforms code assigned by driver, reports the state of computation\n",
    "#### *Cluster Manager-allocates resources, controls driver and manager\n",
    "####  ---- Budget Manager allocates specific amounts (more pay = more work)\n",
    "####  ---- External service for acquiring resources on cluster(stand-alone or another app)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark Parallelism\n",
    "#### *Data broken into partitions-chunk of data sits on physical machine in cluster\n",
    "#### (One partition but many executors-parallelism is only one machine can work with one executor)\n",
    "#### (Many partitions but one executor-parallelism is only one executor assigned to one machine)\n",
    "#### Perfect Parallelism-each executor needs to work on each partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spark APIs\n",
    "#### *Low Level Unstructured API-outdated (RDDs) immutable collection of records operate in parallel\n",
    "#### -----Finely tuned control over data in clusters, maintaining legacy code\n",
    "#### *High-Level API-structured data (CSVs)-Core Forms:\n",
    "#### -----Datasets, Dataframes, SQL tables and views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PySpark in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to put data into dataframes\n",
    "# Schema (structure) for df contains column names/data types\n",
    "# schema can inferre automatically letting spark determine schema or manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "pythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
